{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gdal\n",
    "import ogr\n",
    "import osr\n",
    "import gdalnumeric\n",
    "import gdalconst\n",
    "from osgeo.gdalconst import GA_ReadOnly\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining base functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all Functions\n",
    "\n",
    "def find_band_number(dataset, variable):\n",
    "    '''\n",
    "    Finds the band number and level inside the GRIB file, given the variable\n",
    "    '''\n",
    "    i_list = []\n",
    "    level_list  =[]\n",
    "    for i in range(1,dataset.RasterCount + 1):\n",
    "        band = dataset.GetRasterBand(i)\n",
    "        metadata = band.GetMetadata()\n",
    "        band_level = metadata['GRIB_SHORT_NAME']\n",
    "        band_variable = metadata['GRIB_ELEMENT']\n",
    "        level = band_level[-4:]\n",
    "        if (variable == band_variable) and (level == 'ISBL'):\n",
    "            i_list = i_list + [i]\n",
    "            level = band_level[0:-5]\n",
    "            level_list = level_list + [level]\n",
    "            #return i\n",
    "    return i_list, level_list #retun a list with the number in the band of the variable and its ISBL level\n",
    "\n",
    "def to_DataFrame(xv,yv,lats,longs,level,lat_min,lat_max,long_min,long_max,time):\n",
    "    '''\n",
    "    Converts the data in a DataFrame, format used by Pandas in python\n",
    "    '''\n",
    "    \n",
    "    nb = xv.shape[0]*xv.shape[1]\n",
    "\n",
    "    levels = int(level)*np.ones([nb])\n",
    "    time_list = [time]*nb\n",
    "    xv = np.resize(xv,[nb])\n",
    "    yv = np.resize(yv,[nb])\n",
    "    lats = np.resize(lats,[nb])\n",
    "    longs = np.resize(longs,[nb])\n",
    "    \n",
    "    dic = { 'Wx': xv, 'Wy':yv,'lat':lats,'long':longs,'level':levels,'Timestamp':time_list }\n",
    "    dt = pd.DataFrame(data = dic)\n",
    "    \n",
    "    #dt.columns = ['Wx', 'Wy','lat','long','level','Timestamp']\n",
    "    dt = dt.where(dt.lat >= lat_min)\n",
    "    dt = dt.where(dt.lat <= lat_max)\n",
    "    dt = dt.where(dt.long >= long_min)\n",
    "    dt = dt.where(dt.long <= long_max)\n",
    "    dt = dt.dropna(axis=0, how = 'all')\n",
    "    return dt\n",
    "    \n",
    "def get_Timestamp(Y, M, D, hour, forc):\n",
    "    '''\n",
    "    Take as input the YMD (year, month and day in the format YYYYMMDD), hour (format HH) and forc \n",
    "    (format HHH - hours betweent forecast and simulation). The output is a pandas Timestamp. \n",
    "    '''\n",
    "    hour = hour[0:2]\n",
    "    hour = int(hour)\n",
    "    forc = int(forc)\n",
    "    hour = hour + forc\n",
    "    if hour > 23:\n",
    "        \n",
    "        D = int(D) + int(hour/24)\n",
    "        if D < 10:\n",
    "            D = '0' + str(D)\n",
    "        else:\n",
    "            D = str(D)\n",
    "        hour = hour%24\n",
    "    if hour < 10:\n",
    "        hour = '0'+str(hour)\n",
    "    else:\n",
    "        hour = str(hour)\n",
    "    time = Y + M + D + ' ' + hour\n",
    "    \n",
    "    try:\n",
    "        timestamp =  pd.Timestamp(time)\n",
    "    \n",
    "    except ValueError:\n",
    "        try:\n",
    "            M = int(M) + 1\n",
    "            D = '01'\n",
    "            if M < 10:\n",
    "                M = '0' + str(M)\n",
    "            else:\n",
    "                M = str(M)\n",
    "            time = Y + M + D + ' ' + hour\n",
    "            timestamp =  pd.Timestamp(time)\n",
    "        except:\n",
    "            Y = int(Y) +1\n",
    "            Y = str(Y)\n",
    "            M = '01'\n",
    "            timestamp =  pd.Timestamp(time)\n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining variables to the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the date from the downloaded data to read the data itself and save with the correct informations in the\n",
    "#DataFrame\n",
    "year = '2018'\n",
    "monthh = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "dayy = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16',\n",
    "        '17','18','19','20','21','22','23','24','25','26','27','28','29','30','31']\n",
    "hour = ['0000','0600','1200','1800']\n",
    "forc = list(np.arange(0,121,3))\n",
    "for i in range(len(forc)): \n",
    "    if forc[i] < 10:\n",
    "        forc[i] = '00' + str(forc[i])\n",
    "    elif forc[i] < 100:\n",
    "        forc[i] = '0' + str(forc[i])\n",
    "    else:\n",
    "        forc[i] = str(forc[i])\n",
    "data_type = 'gfs_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the latitude and longitude to be considered\n",
    "\n",
    "# If wanted, define latitude and longitude parameters to get values\n",
    "#Amsterdam\n",
    "#lat_max = 55 #52.3740300\n",
    "#long_max = 7  #4.8896900\n",
    "##London\n",
    "#lat_min = 48 #51.5085300\n",
    "##long_min = -3 #-0.1257400\n",
    "\n",
    "#Else let the following interval to take all globe\n",
    "lat_max = 1000\n",
    "lat_min = -1000\n",
    "long_max = 1000\n",
    "long_min = -1000\n",
    "\n",
    "#if only one level is needed\n",
    "#only_level = '20000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting from grib to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalizing a new list to construct the Dataframe\n",
    "DT = []\n",
    "\n",
    "#looping between the forecast data\n",
    "for month in monthh:\n",
    "    YM = year + month \n",
    "    print(YM)\n",
    "    for day in dayy:\n",
    "        D = day\n",
    "        #print(YM+D)\n",
    "        for i1 in range(len(hour)):\n",
    "            for j1 in range(len(forc)):\n",
    "                hour1 = hour[i1]\n",
    "                forc1 = forc[j1]\n",
    "                file_name = data_type +  '_' +  YM + D + '_'   + hour[i1] + '_' + forc[j1] + '.grb2'\n",
    "                # if necessary change the directory name 'data_Grib' to your own directory name.\n",
    "                data_file = 'data_Grib/' + file_name\n",
    "                #verify if the file do exist or not\n",
    "                if os.path.isfile(data_file):\n",
    "                    #converts the information in a Timestamp\n",
    "                    time = get_Timestamp(year, month, D, hour1, forc1)\n",
    "                    if time == np.nan:\n",
    "                        break    \n",
    "                    #print('YMD:',YMD,'hour:',hour1,'forc',forc1)\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    #The parsing of the Grib is based in: \n",
    "                        #http://geoexamples.blogspot.com/2013/05/drawing-wind-barbs-gdal-python.html\n",
    "                    # importing data from Grib file\n",
    "                    dataset = gdal.Open(data_file, GA_ReadOnly )\n",
    "                    try:\n",
    "                        #get variables\n",
    "                        u_band_id,u_band_level = find_band_number(dataset, 'UGRD')\n",
    "                        v_band_id,v_band_level = find_band_number(dataset, 'VGRD')\n",
    "                        # take only one level if variable is defined\n",
    "                        if 'only_level' in globals():\n",
    "                            ind_lvl = u_band_level.index(only_level)\n",
    "                            u_band_id = [ u_band_id[ind_lvl] ]\n",
    "                        for i in range (len(u_band_id)):\n",
    "                            band_u = dataset.GetRasterBand(u_band_id[i])\n",
    "                            band_v = dataset.GetRasterBand(v_band_id[i])\n",
    "                            level = u_band_level[i]\n",
    "                            geo = dataset.GetGeoTransform()\n",
    "\n",
    "                            xsize = band_u.XSize\n",
    "                            ysize = band_u.YSize\n",
    "\n",
    "                            values_u = band_u.ReadAsArray(0, 0, xsize, ysize)\n",
    "                            values_v = band_v.ReadAsArray(0, 0, xsize, ysize)\n",
    "\n",
    "                            longs = np.arange(geo[0],geo[1]*xsize+geo[0],geo[1])\n",
    "                            lats = np.arange(geo[3],geo[5]*ysize+geo[3],geo[5])\n",
    "                            for j in range(len(longs)):\n",
    "                                if longs[j]>180:\n",
    "                                    longs[j] = longs[j] - 360\n",
    "                            longs, lats = np.meshgrid(longs, lats)\n",
    "\n",
    "                            #converts file to DataFrame\n",
    "                            dt = to_DataFrame(values_u,values_v,lats,longs,level,lat_min,lat_max,long_min,long_max,time)\n",
    "                            #put all DataFrames in a list\n",
    "                            DT =  DT + [dt]\n",
    "                    # to continue in case of an error\n",
    "                    except:\n",
    "                        print('Error in:', file_name)\n",
    "                        continue\n",
    "print('It is over!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.concat(DT) #concatenates all DataFrames in a single one\n",
    "# shows the first lines of the DataFrame\n",
    "my_data.head()\n",
    "# sort values in respect to the Timestamp\n",
    "my_data = my_data.sort_values('Timestamp')\n",
    "# take the name of the file from the keybord\n",
    "name = input(\"Choose a filename: \")\n",
    "# saves the file with the given name and format .hdf\n",
    "file_name =  name + '.hdf'\n",
    "my_data.to_hdf(file_name, 'Wind_vector' ,mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
